<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Model Averaging | STAT 245 Course Notes</title>
  <meta name="description" content="Course notes for the Calvin University course STAT 245, Advanced Data Analysis (a course in applied regression)" />
  <meta name="generator" content="bookdown 0.14 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Model Averaging | STAT 245 Course Notes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Course notes for the Calvin University course STAT 245, Advanced Data Analysis (a course in applied regression)" />
  <meta name="github-repo" content="stacyderuiter/s245-notes-bookdown" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Model Averaging | STAT 245 Course Notes" />
  
  <meta name="twitter:description" content="Course notes for the Calvin University course STAT 245, Advanced Data Analysis (a course in applied regression)" />
  

<meta name="author" content="Stacy DeRuiter, Calvin University" />


<meta name="date" content="2019-10-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regression-for-count-data.html"/>
<link rel="next" href="interactions.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">STAT 245 Notes</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Description</a></li>
<li class="chapter" data-level="2" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>2</b> Linear Regression</a><ul>
<li class="chapter" data-level="2.1" data-path="linear-regression.html"><a href="linear-regression.html#data"><i class="fa fa-check"></i><b>2.1</b> Data</a></li>
<li class="chapter" data-level="2.2" data-path="linear-regression.html"><a href="linear-regression.html#simple-linear-regression-residuals-least-squares"><i class="fa fa-check"></i><b>2.2</b> Simple linear regression, Residuals &amp; Least squares</a><ul>
<li class="chapter" data-level="2.2.1" data-path="linear-regression.html"><a href="linear-regression.html#using-lm-to-fit-a-linear-regression-in-r"><i class="fa fa-check"></i><b>2.2.1</b> Using <code>lm()</code> to fit a linear regression in R</a></li>
<li class="chapter" data-level="2.2.2" data-path="linear-regression.html"><a href="linear-regression.html#equation-of-the-fitted-regression-line"><i class="fa fa-check"></i><b>2.2.2</b> Equation of the fitted regression line</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="linear-regression.html"><a href="linear-regression.html#multiple-regression"><i class="fa fa-check"></i><b>2.3</b> Multiple regression</a><ul>
<li class="chapter" data-level="2.3.1" data-path="linear-regression.html"><a href="linear-regression.html#is-it-really-better"><i class="fa fa-check"></i><b>2.3.1</b> Is it really better?</a></li>
<li class="chapter" data-level="2.3.2" data-path="linear-regression.html"><a href="linear-regression.html#regression-residuals-errors"><i class="fa fa-check"></i><b>2.3.2</b> Regression residuals = “errors”</a></li>
<li class="chapter" data-level="2.3.3" data-path="linear-regression.html"><a href="linear-regression.html#computing-predictions"><i class="fa fa-check"></i><b>2.3.3</b> Computing Predictions</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="linear-regression.html"><a href="linear-regression.html#predictors-with-two-categories"><i class="fa fa-check"></i><b>2.4</b> Predictors with two categories</a><ul>
<li class="chapter" data-level="2.4.1" data-path="linear-regression.html"><a href="linear-regression.html#predictors-with-more-categories"><i class="fa fa-check"></i><b>2.4.1</b> Predictors with more categories</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="linear-regression.html"><a href="linear-regression.html#returning-to-the-r-model-summary"><i class="fa fa-check"></i><b>2.5</b> Returning to the R Model Summary</a></li>
<li class="chapter" data-level="2.6" data-path="linear-regression.html"><a href="linear-regression.html#predictions-from-the-model"><i class="fa fa-check"></i><b>2.6</b> Predictions from the model</a><ul>
<li class="chapter" data-level="2.6.1" data-path="linear-regression.html"><a href="linear-regression.html#by-hand"><i class="fa fa-check"></i><b>2.6.1</b> By Hand</a></li>
<li class="chapter" data-level="2.6.2" data-path="linear-regression.html"><a href="linear-regression.html#prediction-plots-in-r"><i class="fa fa-check"></i><b>2.6.2</b> Prediction Plots in R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="linear-regression.html"><a href="linear-regression.html#why-are-we-doing-this-again"><i class="fa fa-check"></i><b>2.7</b> Why are we doing this again?</a></li>
<li class="chapter" data-level="2.8" data-path="linear-regression.html"><a href="linear-regression.html#shortcut-method---with-uncertainty"><i class="fa fa-check"></i><b>2.8</b> Shortcut Method - With Uncertainty</a><ul>
<li class="chapter" data-level="2.8.1" data-path="linear-regression.html"><a href="linear-regression.html#anatomy-of-a-confidence-interval"><i class="fa fa-check"></i><b>2.8.1</b> Anatomy of a Confidence Interval</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="linear-regression.html"><a href="linear-regression.html#diy-method"><i class="fa fa-check"></i><b>2.9</b> DIY Method</a><ul>
<li class="chapter" data-level="2.9.1" data-path="linear-regression.html"><a href="linear-regression.html#creating-a-hypothetical-dataset"><i class="fa fa-check"></i><b>2.9.1</b> Creating a hypothetical dataset</a></li>
<li class="chapter" data-level="2.9.2" data-path="linear-regression.html"><a href="linear-regression.html#making-the-plot"><i class="fa fa-check"></i><b>2.9.2</b> Making the plot</a></li>
<li class="chapter" data-level="2.9.3" data-path="linear-regression.html"><a href="linear-regression.html#categorical-predictors"><i class="fa fa-check"></i><b>2.9.3</b> Categorical predictors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html"><i class="fa fa-check"></i><b>3</b> Model Selection Using Information Criteria</a><ul>
<li class="chapter" data-level="3.1" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#data-and-model"><i class="fa fa-check"></i><b>3.1</b> Data and Model</a></li>
<li class="chapter" data-level="3.2" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#calculations"><i class="fa fa-check"></i><b>3.2</b> Calculations</a></li>
<li class="chapter" data-level="3.3" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#decisions-with-ics"><i class="fa fa-check"></i><b>3.3</b> Decisions with ICs</a></li>
<li class="chapter" data-level="3.4" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#all-possible-subsets-selection"><i class="fa fa-check"></i><b>3.4</b> All-possible-subsets Selection</a></li>
<li class="chapter" data-level="3.5" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#which-ic-should-i-use"><i class="fa fa-check"></i><b>3.5</b> Which IC should I use?</a></li>
<li class="chapter" data-level="3.6" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#quantities-derived-from-aic"><i class="fa fa-check"></i><b>3.6</b> Quantities derived from AIC</a></li>
<li class="chapter" data-level="3.7" data-path="model-selection-using-information-criteria.html"><a href="model-selection-using-information-criteria.html#important-caution"><i class="fa fa-check"></i><b>3.7</b> Important Caution</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="likelihood.html"><a href="likelihood.html"><i class="fa fa-check"></i><b>4</b> Likelihood</a><ul>
<li class="chapter" data-level="4.1" data-path="likelihood.html"><a href="likelihood.html#data-1"><i class="fa fa-check"></i><b>4.1</b> Data</a></li>
<li class="chapter" data-level="4.2" data-path="likelihood.html"><a href="likelihood.html#review---the-normal-probability-density-function-pdf"><i class="fa fa-check"></i><b>4.2</b> Review - the Normal probability density function (PDF)</a></li>
<li class="chapter" data-level="4.3" data-path="likelihood.html"><a href="likelihood.html#a-simple-model"><i class="fa fa-check"></i><b>4.3</b> A simple model</a></li>
<li class="chapter" data-level="4.4" data-path="likelihood.html"><a href="likelihood.html#using-the-model-to-make-predictions"><i class="fa fa-check"></i><b>4.4</b> Using the Model to Make Predictions</a></li>
<li class="chapter" data-level="4.5" data-path="likelihood.html"><a href="likelihood.html#likelihood-to-the-rescue"><i class="fa fa-check"></i><b>4.5</b> Likelihood to the Rescue!</a></li>
<li class="chapter" data-level="4.6" data-path="likelihood.html"><a href="likelihood.html#how-does-this-relate-to-linear-regression"><i class="fa fa-check"></i><b>4.6</b> How does this relate to linear regression?</a><ul>
<li class="chapter" data-level="4.6.1" data-path="likelihood.html"><a href="likelihood.html#model-equation"><i class="fa fa-check"></i><b>4.6.1</b> Model Equation:</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="likelihood.html"><a href="likelihood.html#likelihood-of-a-dataset-given-a-model"><i class="fa fa-check"></i><b>4.7</b> Likelihood of a dataset, given a model</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html"><i class="fa fa-check"></i><b>5</b> PDFs and PMFs</a><ul>
<li class="chapter" data-level="5.1" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#beyond-normal"><i class="fa fa-check"></i><b>5.1</b> Beyond Normal</a></li>
<li class="chapter" data-level="5.2" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#types-of-probability-distributions"><i class="fa fa-check"></i><b>5.2</b> Types of probability distributions</a><ul>
<li class="chapter" data-level="5.2.1" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#continuous-distributions"><i class="fa fa-check"></i><b>5.2.1</b> Continuous distributions</a></li>
<li class="chapter" data-level="5.2.2" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#discrete-distributions"><i class="fa fa-check"></i><b>5.2.2</b> Discrete Distributions</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#relevant-features-of-distributions"><i class="fa fa-check"></i><b>5.3</b> Relevant Features of Distributions</a></li>
<li class="chapter" data-level="5.4" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#examples-of-continuous-distributions"><i class="fa fa-check"></i><b>5.4</b> Examples of Continuous Distributions</a><ul>
<li class="chapter" data-level="5.4.1" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#normal"><i class="fa fa-check"></i><b>5.4.1</b> Normal</a></li>
<li class="chapter" data-level="5.4.2" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#gamma"><i class="fa fa-check"></i><b>5.4.2</b> Gamma</a></li>
<li class="chapter" data-level="5.4.3" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#beta"><i class="fa fa-check"></i><b>5.4.3</b> Beta</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#examples-of-discrete-distributions"><i class="fa fa-check"></i><b>5.5</b> Examples of Discrete Distributions</a><ul>
<li class="chapter" data-level="5.5.1" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#binomial"><i class="fa fa-check"></i><b>5.5.1</b> Binomial</a></li>
<li class="chapter" data-level="5.5.2" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#poisson"><i class="fa fa-check"></i><b>5.5.2</b> Poisson</a></li>
<li class="chapter" data-level="5.5.3" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#negative-binomial"><i class="fa fa-check"></i><b>5.5.3</b> Negative Binomial</a></li>
<li class="chapter" data-level="5.5.4" data-path="pdfs-and-pmfs.html"><a href="pdfs-and-pmfs.html#a-mixture-distribution-tweedie"><i class="fa fa-check"></i><b>5.5.4</b> A Mixture Distribution: Tweedie</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html"><i class="fa fa-check"></i><b>6</b> Regression for Count Data</a><ul>
<li class="chapter" data-level="6.1" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#data-source"><i class="fa fa-check"></i><b>6.1</b> Data Source</a></li>
<li class="chapter" data-level="6.2" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#a-bad-idea-multiple-linear-regression-model"><i class="fa fa-check"></i><b>6.2</b> A bad idea: multiple linear regression model</a></li>
<li class="chapter" data-level="6.3" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#problems-with-the-linear-model"><i class="fa fa-check"></i><b>6.3</b> Problems with the linear model</a></li>
<li class="chapter" data-level="6.4" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#poisson-regression"><i class="fa fa-check"></i><b>6.4</b> Poisson Regression</a><ul>
<li class="chapter" data-level="6.4.1" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#fitting-the-model"><i class="fa fa-check"></i><b>6.4.1</b> Fitting the Model</a></li>
<li class="chapter" data-level="6.4.2" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#conditions"><i class="fa fa-check"></i><b>6.4.2</b> Conditions</a></li>
<li class="chapter" data-level="6.4.3" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#model-assessment"><i class="fa fa-check"></i><b>6.4.3</b> Model Assessment</a></li>
<li class="chapter" data-level="6.4.4" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#checking-for-overdispersion-using-overdispersion-factor"><i class="fa fa-check"></i><b>6.4.4</b> Checking for overdispersion using overdispersion factor</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#accounting-for-overdispersion-negative-binomial-models"><i class="fa fa-check"></i><b>6.5</b> Accounting for overdispersion: Negative Binomial Models</a></li>
<li class="chapter" data-level="6.6" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#accounting-for-overdispersion-quasi-poisson-model"><i class="fa fa-check"></i><b>6.6</b> Accounting for overdispersion: quasi-Poisson Model</a></li>
<li class="chapter" data-level="6.7" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#model-selection-with-dredge-and-qaic-bic"><i class="fa fa-check"></i><b>6.7</b> Model selection with dredge() and (Q)AIC, BIC</a><ul>
<li class="chapter" data-level="6.7.1" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#review-all-subsets-selection-with-dredge"><i class="fa fa-check"></i><b>6.7.1</b> Review: all subsets selection with dredge()</a></li>
<li class="chapter" data-level="6.7.2" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#review-ic-weights"><i class="fa fa-check"></i><b>6.7.2</b> Review: IC “weights”</a></li>
<li class="chapter" data-level="6.7.3" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#extending-dredge-to-quasi-likelihood"><i class="fa fa-check"></i><b>6.7.3</b> Extending dredge() to quasi-Likelihood</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#offsets"><i class="fa fa-check"></i><b>6.8</b> Offsets</a></li>
<li class="chapter" data-level="6.9" data-path="regression-for-count-data.html"><a href="regression-for-count-data.html#prediction-plots"><i class="fa fa-check"></i><b>6.9</b> Prediction Plots</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="model-averaging.html"><a href="model-averaging.html"><i class="fa fa-check"></i><b>7</b> Model Averaging</a><ul>
<li class="chapter" data-level="7.1" data-path="model-averaging.html"><a href="model-averaging.html#data-school-survey-on-crime-and-safety"><i class="fa fa-check"></i><b>7.1</b> Data: School Survey on Crime and Safety</a></li>
<li class="chapter" data-level="7.2" data-path="model-averaging.html"><a href="model-averaging.html#modelling-number-of-violent-incidents-per-school"><i class="fa fa-check"></i><b>7.2</b> Modelling number of violent incidents per school</a></li>
<li class="chapter" data-level="7.3" data-path="model-averaging.html"><a href="model-averaging.html#model-averaging-1"><i class="fa fa-check"></i><b>7.3</b> Model Averaging</a><ul>
<li class="chapter" data-level="7.3.1" data-path="model-averaging.html"><a href="model-averaging.html#getting-the-averaged-model"><i class="fa fa-check"></i><b>7.3.1</b> Getting the Averaged Model</a></li>
<li class="chapter" data-level="7.3.2" data-path="model-averaging.html"><a href="model-averaging.html#getting-predictions-from-the-averaged-model"><i class="fa fa-check"></i><b>7.3.2</b> Getting Predictions from the Averaged Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="interactions.html"><a href="interactions.html"><i class="fa fa-check"></i><b>8</b> Interactions</a><ul>
<li class="chapter" data-level="8.1" data-path="interactions.html"><a href="interactions.html#example-quantitative-categorical-interaction"><i class="fa fa-check"></i><b>8.1</b> Example: Quantitative-Categorical Interaction</a></li>
<li class="chapter" data-level="8.2" data-path="interactions.html"><a href="interactions.html#categorical-categorical-interaction-example"><i class="fa fa-check"></i><b>8.2</b> Categorical-Categorical Interaction Example</a></li>
<li class="chapter" data-level="8.3" data-path="interactions.html"><a href="interactions.html#quant-quant-interactions"><i class="fa fa-check"></i><b>8.3</b> Quant-Quant interactions?</a></li>
<li class="chapter" data-level="8.4" data-path="interactions.html"><a href="interactions.html#r-code"><i class="fa fa-check"></i><b>8.4</b> R code</a></li>
<li class="chapter" data-level="8.5" data-path="interactions.html"><a href="interactions.html#cautionary-note"><i class="fa fa-check"></i><b>8.5</b> Cautionary note</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="binary-regression.html"><a href="binary-regression.html"><i class="fa fa-check"></i><b>9</b> Binary Regression</a><ul>
<li class="chapter" data-level="9.1" data-path="binary-regression.html"><a href="binary-regression.html#data-source-1"><i class="fa fa-check"></i><b>9.1</b> Data Source</a></li>
<li class="chapter" data-level="9.2" data-path="binary-regression.html"><a href="binary-regression.html#logistic-regression"><i class="fa fa-check"></i><b>9.2</b> Logistic Regression</a></li>
<li class="chapter" data-level="9.3" data-path="binary-regression.html"><a href="binary-regression.html#checking-the-data-setup"><i class="fa fa-check"></i><b>9.3</b> Checking the data setup</a></li>
<li class="chapter" data-level="9.4" data-path="binary-regression.html"><a href="binary-regression.html#fitting-a-saturated-model"><i class="fa fa-check"></i><b>9.4</b> Fitting a saturated model</a></li>
<li class="chapter" data-level="9.5" data-path="binary-regression.html"><a href="binary-regression.html#link-functions"><i class="fa fa-check"></i><b>9.5</b> Link Functions</a></li>
<li class="chapter" data-level="9.6" data-path="binary-regression.html"><a href="binary-regression.html#conditions-1"><i class="fa fa-check"></i><b>9.6</b> Conditions</a></li>
<li class="chapter" data-level="9.7" data-path="binary-regression.html"><a href="binary-regression.html#model-assessment-plots"><i class="fa fa-check"></i><b>9.7</b> Model Assessment Plots</a></li>
<li class="chapter" data-level="9.8" data-path="binary-regression.html"><a href="binary-regression.html#odds-ratios"><i class="fa fa-check"></i><b>9.8</b> Odds Ratios</a></li>
<li class="chapter" data-level="9.9" data-path="binary-regression.html"><a href="binary-regression.html#model-selection"><i class="fa fa-check"></i><b>9.9</b> Model Selection</a></li>
<li class="chapter" data-level="9.10" data-path="binary-regression.html"><a href="binary-regression.html#prediction-plots-1"><i class="fa fa-check"></i><b>9.10</b> Prediction Plots</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html"><i class="fa fa-check"></i><b>10</b> Binary regression: Data with more than one trial per row</a><ul>
<li class="chapter" data-level="10.1" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html#data-2"><i class="fa fa-check"></i><b>10.1</b> Data</a></li>
<li class="chapter" data-level="10.2" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html#checking-the-data-setup-1"><i class="fa fa-check"></i><b>10.2</b> Checking the data setup</a></li>
<li class="chapter" data-level="10.3" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html#fitting-a-saturated-model-1"><i class="fa fa-check"></i><b>10.3</b> Fitting a saturated model</a></li>
<li class="chapter" data-level="10.4" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html#checking-linearity"><i class="fa fa-check"></i><b>10.4</b> Checking linearity</a></li>
<li class="chapter" data-level="10.5" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html#model-assessment-1"><i class="fa fa-check"></i><b>10.5</b> Model Assessment</a></li>
<li class="chapter" data-level="10.6" data-path="binary-regression-data-with-more-than-one-trial-per-row.html"><a href="binary-regression-data-with-more-than-one-trial-per-row.html#model-selection-1"><i class="fa fa-check"></i><b>10.6</b> Model Selection</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">STAT 245 Course Notes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="model-averaging" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Model Averaging</h1>
<p>So far, we have used AIC and/or BIC for model selection, to decide which variables to keep in a “best” model and which to exclude. But we have already seen a number of cases where there is not <strong>one</strong> model that is clearly superior to all the others. In those cases, we have decided on the smallest model (with the fewest predictors), but there are other options when many competing models have similar scores.</p>
<p>One option is <em>not to choose</em> – instead, keep them all, and make predictions via a weighted average of all the models. The models with the best IC scores get more weight. This can be a good option if the main goal is accurate prediction (rather than deciding definitively which predictors are “good” ones and which are not).</p>
<p>How can we do it? Let’s explore an example.</p>
<div id="data-school-survey-on-crime-and-safety" class="section level2">
<h2><span class="header-section-number">7.1</span> Data: School Survey on Crime and Safety</h2>
<p>The data for this example are from a survey of U.S. schools, the 2000 School Survey on Crime and Safety. There is information about the study at</p>
<p><a href="http://catalog.data.gov/dataset/2000-school-survey-on-crime-and-safety">http://catalog.data.gov/dataset/2000-school-survey-on-crime-and-safety</a>,</p>
<p>which says the study “is a cross-sectional survey of the nation’s public schools designed to provide estimates of school crime, discipline, disorder, programs and policies. SSOCS is administered to public primary, middle, high, and combined school principals in the spring of even-numbered school years…Public schools were sampled in the spring of 2000 to participate in the study.”</p>
<p>The dataset you will use is available online at:</p>
<p><a href="http://sldr.netlfiy.com/data/sscrime.csv">http://sldr.netlify.com/data/sscrime.csv</a></p>
<p>It contains a number of variables:</p>
<ul>
<li><code>VisitorCheckIn</code>: Whether visitors to the school must check in to gain entry to the school.</li>
<li><code>LockedGates</code>: Whether there are locked gates at the entry to the school.</li>
<li><code>MetalDetectors</code>: Whether there is a metal detector at the entrance to the school.</li>
<li><code>DrugSniffDog</code>: Whether a drug-sniffing dog is randomly brought into the school to carry out inspections.</li>
<li><code>DrugTesting</code>: Whether any drug testing of students occurs.</li>
<li><code>UniformsRequired</code>:Whether students are required to wear uniforms.</li>
<li><code>DressCode</code>: Whether a strict dress code is enforced.</li>
<li><code>Lockers</code>: Whether students have lockers.</li>
<li><code>StudentIDBadges</code>: Whether students are required to wear ID badges.</li>
<li><code>StaffIDBadges</code>: Whether teachers and other staff are required to wear ID badges.</li>
<li><code>SecurityCameras</code>: Whether there are security cameras on the premises.</li>
<li><code>OfficialRiotPlan</code>: Whether the school has a written plan in place for how to deal with a riot or large-scale fight.</li>
<li><code>ViolenceReductionProgram</code>: Whether the school has a Violence Reduction Program in place.</li>
<li><code>Security</code>: Whether security officers are present on the premises.</li>
<li><code>TrainingHours</code>: Average amount of time (in hours) that teachers and staff have devoted to training related to violence reduction.</li>
<li><code>AttacksWithoutWeapon</code>: Number of attacks that have occurred at the school, not involving a weapon.</li>
<li><code>Thefts</code>: Number of thefts.</li>
<li><code>Vandalism</code>: Number of incidents of vandalism.</li>
<li><code>ViolentIncidentsTotal</code>: Number of violent incidents of all types that have occurred at the school.</li>
<li><code>Enrollment</code>: Number of students enrolled in the school (categorical)</li>
<li><code>NEnrollment</code>: Number of students enrolled in the school (numeric)</li>
<li><code>SurveyRespondent</code>: The identity of the person who filled out the survey.</li>
<li><code>Location</code>: Whether the location of the school is Urban, Rural, etc.</li>
</ul>
<div class="sourceCode" id="cb90"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb90-1" title="1">ssc &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;http://sldr.netlify.com/data/sscrime.csv&#39;</span>)</a></code></pre></div>
</div>
<div id="modelling-number-of-violent-incidents-per-school" class="section level2">
<h2><span class="header-section-number">7.2</span> Modelling number of violent incidents per school</h2>
<p>We will fit a model for the number of violent incidents total as a function of a number of predictors. This is count data and we will fit a negative binomial regression model:</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb91-1" title="1"><span class="kw">require</span>(glmmTMB)</a>
<a class="sourceLine" id="cb91-2" title="2">school.nb2 &lt;-<span class="st"> </span><span class="kw">glmmTMB</span>(ViolentIncidentsTotal <span class="op">~</span><span class="st"> </span>TrainingHours <span class="op">+</span><span class="st"> </span>Location <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb91-3" title="3"><span class="st">                        </span>SecurityCameras <span class="op">+</span><span class="st"> </span>DressCode <span class="op">+</span><span class="st"> </span>UniformsRequired <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb91-4" title="4"><span class="st">                        </span>NEnrollment, <span class="dt">data=</span>ssc,</a>
<a class="sourceLine" id="cb91-5" title="5">                <span class="dt">family=</span><span class="kw">nbinom2</span>(<span class="dt">link=</span><span class="st">&#39;log&#39;</span>))</a></code></pre></div>
<p>I will use AIC and the <code>dredge()</code> function to compare all possible subsets of my saturated model and figure out which variables should be included in the best model. I chose AIC in this case because it is perhaps more widely used than BIC (that’s not a good reason unless you really have no better one, but there you have it) and because with the relatively small sample size here, I don’t feel a particular need to use BIC for its larger penalty term.</p>
<div class="sourceCode" id="cb92"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb92-1" title="1"><span class="kw">require</span>(MuMIn)</a>
<a class="sourceLine" id="cb92-2" title="2"><span class="co">#do &quot;dredge&quot; for model selection</span></a>
<a class="sourceLine" id="cb92-3" title="3">mod.sel &lt;-<span class="st"> </span><span class="kw">dredge</span>(school.nb2, <span class="dt">rank=</span><span class="st">&#39;AIC&#39;</span>)</a>
<a class="sourceLine" id="cb92-4" title="4"><span class="kw">head</span>(mod.sel, <span class="dv">8</span>)</a></code></pre></div>
<pre><code>## Global model call: glmmTMB(formula = ViolentIncidentsTotal ~ TrainingHours + Location + 
##     SecurityCameras + DressCode + UniformsRequired + NEnrollment, 
##     data = ssc, family = nbinom2(link = &quot;log&quot;), ziformula = ~0, 
##     dispformula = ~1)
## ---
## Model selection table 
##    cnd((Int)) dsp((Int)) cnd(DrC) cnd(Lct)  cnd(NEn) cnd(ScC)  cnd(TrH)
## 4       3.610          +        +        +                             
## 36      3.585          +        +        +                             
## 12      3.635          +        +        +                  +          
## 8       3.570          +        +        + 2.537e-05                   
## 20      3.608          +        +        +                    0.0008916
## 44      3.610          +        +        +                  +          
## 40      3.529          +        +        + 3.410e-05                   
## 16      3.588          +        +        + 3.140e-05        +          
##    cnd(UnR) df    logLik    AIC delta weight
## 4            6 -1745.380 3502.8  0.00  0.287
## 36        +  7 -1745.017 3504.0  1.27  0.152
## 12           7 -1745.103 3504.2  1.45  0.139
## 8            7 -1745.280 3504.6  1.80  0.117
## 20           7 -1745.380 3504.8  2.00  0.106
## 44        +  8 -1744.734 3505.5  2.71  0.074
## 40        +  8 -1744.840 3505.7  2.92  0.067
## 16           8 -1744.953 3505.9  3.15  0.060
## Models ranked by AIC(x)</code></pre>
<p>Because the first 7 or so models all have AIC scores within 3 units of each other, it is hard to choose one best model here. In this situation, one way to choose is to pick the model that includes the smallest number of predictors, and still acheives an AIC that is among the best. Another option would be to use <strong>model averaging</strong>.</p>
</div>
<div id="model-averaging-1" class="section level2">
<h2><span class="header-section-number">7.3</span> Model Averaging</h2>
<p>What if we wanted to use model averaging to find the best model, instead? We might choose this route because there are several models that all have AIC that are close to each other and thus fit the data approximately equally well. So we might choose to make predictions (and compute coefficients) that are the <em>average</em> of all the models (weighted by IC weights).</p>
<p>Notes of caution:</p>
<ul>
<li>If the model is not a linear regression (if there is a link function for instance) then it’s important to get <strong>predictions</strong> by <em>averaging the predictions from the different models</em>, <strong>not</strong> by making predictions using the model-averaged coefficients. The code below is careful to do this.</li>
<li>Model averaging is used pretty widely but is also controversial (like most model selection methods, in fact!) For example, see: [<a href="https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/14-1639.1" class="uri">https://esajournals.onlinelibrary.wiley.com/doi/full/10.1890/14-1639.1</a>] and [<a href="https://drewtyre.rbind.io/post/rebutting_cade/" class="uri">https://drewtyre.rbind.io/post/rebutting_cade/</a>].</li>
</ul>
<p>To do model averaging, we use package <code>MuMIn</code> (function <code>model.avg</code>).</p>
<div id="getting-the-averaged-model" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Getting the Averaged Model</h3>
<p>The following code gets the average model. If we did the default (<code>fit=FALSE</code>), it would be a bit faster, but we would then not be able to get predictions from the model.</p>
<div class="sourceCode" id="cb94"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb94-1" title="1">mod.sel2 &lt;-<span class="st"> </span><span class="kw">dredge</span>(school.nb2)</a>
<a class="sourceLine" id="cb94-2" title="2">ave.model &lt;-<span class="st"> </span>MuMIn<span class="op">::</span><span class="kw">model.avg</span>(mod.sel2, <span class="dt">fit=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb94-3" title="3"><span class="kw">summary</span>(ave.model)</a></code></pre></div>
<pre><code>## 
## Call:
## model.avg(object = get.models(object = mod.sel2, subset = NA))
## 
## Component model call: 
## glmmTMB(formula = ViolentIncidentsTotal ~ &lt;64 unique rhs&gt;, data = 
##      ssc, family = nbinom2(link = &quot;log&quot;), ziformula = ~0, dispformula = 
##      ~1)
## 
## Component models: 
##        df   logLik    AICc delta weight
## 12      6 -1745.38 3502.98  0.00   0.24
## 126     7 -1745.02 3504.33  1.35   0.12
## 124     7 -1745.10 3504.51  1.52   0.11
## 123     7 -1745.28 3504.86  1.88   0.09
## 125     7 -1745.38 3505.06  2.08   0.08
## 1246    8 -1744.73 3505.86  2.87   0.06
## 1236    8 -1744.84 3506.07  3.08   0.05
## 1234    8 -1744.95 3506.29  3.31   0.05
## 1256    8 -1745.02 3506.42  3.44   0.04
## 1245    8 -1745.10 3506.59  3.60   0.04
## 1235    8 -1745.28 3506.95  3.96   0.03
## 12346   9 -1744.49 3507.46  4.48   0.03
## 12456   9 -1744.73 3507.95  4.96   0.02
## 12356   9 -1744.84 3508.17  5.18   0.02
## 12345   9 -1744.95 3508.38  5.40   0.02
## 123456 10 -1744.48 3509.56  6.58   0.01
## 2       5 -1753.09 3516.33 13.35   0.00
## 26      6 -1752.29 3516.80 13.82   0.00
## 24      6 -1752.60 3517.42 14.44   0.00
## 246     7 -1751.79 3517.87 14.89   0.00
## 25      6 -1753.09 3518.40 15.41   0.00
## 23      6 -1753.09 3518.40 15.41   0.00
## 236     7 -1752.26 3518.82 15.84   0.00
## 256     7 -1752.29 3518.87 15.89   0.00
## 234     7 -1752.59 3519.48 16.49   0.00
## 245     7 -1752.59 3519.49 16.50   0.00
## 2346    8 -1751.72 3519.82 16.83   0.00
## 2456    8 -1751.78 3519.96 16.97   0.00
## 235     7 -1753.09 3520.47 17.49   0.00
## 2356    8 -1752.26 3520.90 17.92   0.00
## 2345    8 -1752.59 3521.56 18.57   0.00
## 23456   9 -1751.71 3521.91 18.92   0.00
## 136     5 -1756.63 3523.42 20.43   0.00
## 1346    6 -1756.08 3524.39 21.41   0.00
## 13      4 -1758.25 3524.60 21.62   0.00
## 16      4 -1758.59 3525.28 22.29   0.00
## 1356    6 -1756.61 3525.44 22.45   0.00
## 134     5 -1757.74 3525.65 22.66   0.00
## 1       3 -1759.81 3525.68 22.69   0.00
## 13456   7 -1756.08 3526.46 23.48   0.00
## 135     5 -1758.21 3526.59 23.60   0.00
## 146     5 -1758.30 3526.76 23.78   0.00
## 14      4 -1759.53 3527.16 24.17   0.00
## 156     5 -1758.54 3527.24 24.26   0.00
## 15      4 -1759.75 3527.61 24.62   0.00
## 1345    6 -1757.73 3527.69 24.71   0.00
## 1456    6 -1758.28 3528.79 25.80   0.00
## 145     5 -1759.50 3529.15 26.17   0.00
## 36      4 -1765.82 3539.76 36.77   0.00
## 346     5 -1764.96 3540.08 37.10   0.00
## 6       3 -1767.12 3540.31 37.33   0.00
## 46      4 -1766.54 3541.19 38.20   0.00
## 356     5 -1765.77 3541.70 38.71   0.00
## 3456    6 -1764.95 3542.12 39.14   0.00
## 56      4 -1767.04 3542.18 39.20   0.00
## (Null)  2 -1769.34 3542.72 39.74   0.00
## 3       3 -1768.50 3543.05 40.07   0.00
## 456     5 -1766.50 3543.17 40.18   0.00
## 34      4 -1767.71 3543.52 40.54   0.00
## 4       3 -1768.77 3543.61 40.63   0.00
## 5       3 -1769.24 3544.54 41.55   0.00
## 35      4 -1768.41 3544.93 41.95   0.00
## 345     5 -1767.68 3545.51 42.53   0.00
## 45      4 -1768.72 3545.54 42.55   0.00
## 
## Term codes: 
##        cond(DressCode)         cond(Location)      cond(NEnrollment) 
##                      1                      2                      3 
##  cond(SecurityCameras)    cond(TrainingHours) cond(UniformsRequired) 
##                      4                      5                      6 
## 
## Model-averaged coefficients:  
## (full average) 
##                              Estimate Std. Error Adjusted SE z value
## cond((Int))                 3.596e+00  1.316e-01   1.320e-01  27.252
## cond(DressCodeyes)          3.765e-01  9.608e-02   9.639e-02   3.906
## cond(LocationRural)        -5.597e-01  1.328e-01   1.332e-01   4.201
## cond(LocationTown)         -5.874e-01  1.543e-01   1.548e-01   3.795
## cond(LocationUrban Fringe) -1.024e-01  1.179e-01   1.183e-01   0.866
## cond(UniformsRequiredyes)   5.685e-02  1.373e-01   1.376e-01   0.413
## cond(SecurityCamerasyes)   -2.384e-02  6.451e-02   6.466e-02   0.369
## cond(NEnrollment)           8.826e-06  2.812e-05   2.818e-05   0.313
## cond(TrainingHours)        -2.156e-04  2.509e-02   2.517e-02   0.009
##                            Pr(&gt;|z|)    
## cond((Int))                 &lt; 2e-16 ***
## cond(DressCodeyes)         9.39e-05 ***
## cond(LocationRural)        2.65e-05 ***
## cond(LocationTown)         0.000148 ***
## cond(LocationUrban Fringe) 0.386523    
## cond(UniformsRequiredyes)  0.679432    
## cond(SecurityCamerasyes)   0.712383    
## cond(NEnrollment)          0.754163    
## cond(TrainingHours)        0.993166    
##  
## (conditional average) 
##                              Estimate Std. Error Adjusted SE z value
## cond((Int))                 3.596e+00  1.316e-01   1.320e-01  27.252
## cond(DressCodeyes)          3.771e-01  9.499e-02   9.530e-02   3.956
## cond(LocationRural)        -5.598e-01  1.328e-01   1.332e-01   4.203
## cond(LocationTown)         -5.874e-01  1.542e-01   1.547e-01   3.796
## cond(LocationUrban Fringe) -1.024e-01  1.179e-01   1.183e-01   0.866
## cond(UniformsRequiredyes)   1.661e-01  1.921e-01   1.927e-01   0.862
## cond(SecurityCamerasyes)   -7.409e-02  9.597e-02   9.628e-02   0.770
## cond(NEnrollment)           3.049e-05  4.550e-05   4.565e-05   0.668
## cond(TrainingHours)        -8.265e-04  4.912e-02   4.928e-02   0.017
##                            Pr(&gt;|z|)    
## cond((Int))                 &lt; 2e-16 ***
## cond(DressCodeyes)         7.61e-05 ***
## cond(LocationRural)        2.63e-05 ***
## cond(LocationTown)         0.000147 ***
## cond(LocationUrban Fringe) 0.386505    
## cond(UniformsRequiredyes)  0.388948    
## cond(SecurityCamerasyes)   0.441588    
## cond(NEnrollment)          0.504120    
## cond(TrainingHours)        0.986617    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p><strong>If you are trying to get model-averaged coefficients from the summary output above, be sure to look for the “full average” ones and not the “conditional average” (which only includes models where the predictor was included, i.e., where the coefficient was not 0).</strong></p>
</div>
<div id="getting-predictions-from-the-averaged-model" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Getting Predictions from the Averaged Model</h3>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb96-1" title="1">ma.preds &lt;-<span class="st"> </span><span class="kw">predict</span>(ave.model, <span class="dt">se.fit=</span><span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb96-2" title="2">                    <span class="dt">type =</span> <span class="st">&#39;response&#39;</span>, </a>
<a class="sourceLine" id="cb96-3" title="3">                    <span class="dt">backtransform =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>The resulting predictions are a list with entries <code>fit</code> and <code>se.fit</code> just like we are used to. (So you could make predictions with a <code>newdata</code> data set and use them for prediction plots, for example. Be careful – your “new” dataset now has to include values for all candidate predictors in the full model.)</p>
<p>Comparing with the predictions from our previous “best” model:</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb97-1" title="1">best.school.nb2 &lt;-<span class="st"> </span><span class="kw">glmmTMB</span>(ViolentIncidentsTotal <span class="op">~</span><span class="st"> </span>DressCode <span class="op">+</span><span class="st"> </span>Location,</a>
<a class="sourceLine" id="cb97-2" title="2">                           <span class="dt">data=</span>ssc,<span class="dt">family=</span><span class="kw">nbinom2</span>(<span class="dt">link=</span><span class="st">&#39;log&#39;</span>))</a>
<a class="sourceLine" id="cb97-3" title="3"></a>
<a class="sourceLine" id="cb97-4" title="4"></a>
<a class="sourceLine" id="cb97-5" title="5"><span class="kw">pred_plot</span>(ave.model, <span class="st">&#39;DressCode&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;N. Incidents&#39;</span>,</a>
<a class="sourceLine" id="cb97-6" title="6">            <span class="dt">data =</span> ssc, <span class="dt">color =</span> <span class="st">&#39;red&#39;</span>)</a>
<a class="sourceLine" id="cb97-7" title="7"></a>
<a class="sourceLine" id="cb97-8" title="8"><span class="kw">pred_plot</span>(best.school.nb2, <span class="st">&#39;DressCode&#39;</span>, <span class="dt">ylab =</span> <span class="st">&#39;N. Incidents&#39;</span>,) </a></code></pre></div>
<p><img src="s245-notes_files/figure-html/unnamed-chunk-56-1.png" width="312" /><img src="s245-notes_files/figure-html/unnamed-chunk-56-2.png" width="312" /></p>
<p>So they are pretty comparable, but a little different (the differences may be bigger the more there are different models with similar IC results contributing to the average model – when one model carries almost all the weight, then the “single best” model and the model-averaging model will give almost the same results). It also makes sense that there will be a bit more uncertainty in the average model.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regression-for-count-data.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interactions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/07-model-averaging.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": ["s245-notes.pdf", "s245-notes.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
